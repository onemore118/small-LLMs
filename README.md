# small-LLMs
Collecting Small-Scale Open-Source LLM Models

A development branch of large language models is aimed at those that can operate on personal computers or machines with lower specifications. However, what's even more appealing is that by combining these small-scale models with high-quality data, multiple expert models can be trained. An heterogeneous architecture, where large language models handle parsing and small models handle expert domain computations, may be one of the directions for future development.

Thus, this repository is used to collect the currently advanced models on the market that can run on lower-spec machines, either as small models or as quantized variants of larger models.

## LLAMAs
[karpathy/llama2.c](https://github.com/karpathy/llama2.c)

[trholding/llama2.c](https://github.com/trholding/llama2.c)


## Other
[mistral 7B](https://mistral.ai/)
